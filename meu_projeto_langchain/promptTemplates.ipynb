{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "243181e6",
   "metadata": {},
   "source": [
    "# Prompt Template no LangChain \n",
    "\n",
    "Um Prompt Template no LangChain é uma forma estruturada de criar prompts dinâmicos para modelos de linguagem. Ele permite que você defina um \"molde\" de prompt com espaços reservados (variáveis), que podem ser preenchidos com diferentes valores em tempo de execução."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b29a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.llms import OpenAI\n",
    "\n",
    "llm=OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edfd14f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template=PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Responda a seguinte pergunta do usuario\n",
    "    {pergunta}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b3a82f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    Responda a seguinte pergunta do usuario\\n    o que é SSAS?\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.format(pergunta=\"o que é SSAS?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdf1d0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template=PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Responda a seguinte pergunta do usuario em até {n_pal} palavras\n",
    "    {pergunta}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de81e4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template=PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Responda a seguinte pergunta do usuario em até {n_pal} palavras\n",
    "    {pergunta}\n",
    "\"\"\",partial_variables={\"n_pal\":30}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10efd6da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    Responda a seguinte pergunta do usuario em até 30 palavras\\n    o que é SSAS?\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.format(pergunta=\"o que é SSAS?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e1a99d",
   "metadata": {},
   "source": [
    "### multiplos prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "654a4138",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "templat_word_cont=PromptTemplate.from_template(\"\"\"\n",
    "    Responda as pegunta em até {n_p} palavras\n",
    "\"\"\")\n",
    "templat_linha_cont=PromptTemplate.from_template(\"\"\"\n",
    "    Responda as pegunta em até {n_l} linhas\n",
    "\"\"\")\n",
    "templat_idioma=PromptTemplate.from_template(\"\"\"\n",
    "    Responda as pegunta em {n_i}\n",
    "\"\"\")\n",
    "\n",
    "template_final=(templat_word_cont+templat_linha_cont+ templat_idioma+\"responda senguindo as instruções {pergunta}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "151719cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Responda as pegunta em até 20 palavras\n",
      "\n",
      "    Responda as pegunta em até 20 linhas\n",
      "\n",
      "    Responda as pegunta em inglês\n",
      "responda senguindo as instruções o que sest?\n"
     ]
    }
   ],
   "source": [
    "promptFinal=template_final.format(n_p=20, n_l=20, n_i=\"inglês\", pergunta=\"o que sest?\")\n",
    "print(promptFinal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98ae678",
   "metadata": {},
   "source": [
    "## Tamplates para chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a1b3a71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Essa e mina duvida: quem é você?', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "chatTemplete=ChatPromptTemplate.from_template(\"Essa e mina duvida: {duvida}\")\n",
    "chatTemplete.format_messages(duvida=\"quem é você?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db3f96f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Essa e mina duvida: quem é você?', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "chatTemplete=ChatPromptTemplate.from_template(\"Essa e mina duvida: {duvida}\")\n",
    "chatTemplete.format_messages(duvida=\"quem é você?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f0c3814",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "chatTemplate = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Você é um assistente irônico e se chama {nome_assistente}.\"),\n",
    "    (\"human\", \"Olá, como vai?\"),\n",
    "    (\"ai\", \"Claro que não estou bem, como posso não ajudar?\"),\n",
    "    (\"human\", \"{pergunta}\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "03e38bc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Você é um assistente irônico e se chama abelardo.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Olá, como vai?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Claro que não estou bem, como posso não ajudar?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='o que é sas?', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatTemplate.format_messages(nome_assistente=\"abelardo\",pergunta=\"o que é sas?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99192323",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# Define o template do chat\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Você é um assistente sarcástico e engraçado.\"),\n",
    "    (\"human\", \"{pergunta}\")\n",
    "])\n",
    "\n",
    "# Inicializa o modelo\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", openai_api_key=\"sua_chave_aqui\")\n",
    "\n",
    "# Cria a cadeia de execução\n",
    "chain = LLMChain(llm=llm, prompt=template)\n",
    "\n",
    "# Executa com uma pergunta\n",
    "resposta = chain.run(pergunta=\"O que é memória RAM?\")\n",
    "print(resposta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac097558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HUMAN: Qual é a capital da França?\n",
      "AI: A capital da França é Paris.\n",
      "HUMAN: Quem escreveu Dom Casmurro?\n",
      "AI: Dom Casmurro foi escrito por Machado de Assis.\n",
      "HUMAN: Qual é a fórmula da água?\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema import HumanMessage, AIMessage\n",
    "\n",
    "# Exemplo de mensagens few-shot\n",
    "examples = [\n",
    "    HumanMessage(content=\"Qual é a capital da França?\"),\n",
    "    AIMessage(content=\"A capital da França é Paris.\"),\n",
    "    \n",
    "    HumanMessage(content=\"Quem escreveu Dom Casmurro?\"),\n",
    "    AIMessage(content=\"Dom Casmurro foi escrito por Machado de Assis.\"),\n",
    "]\n",
    "\n",
    "# Template para nova pergunta\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    messages=[\n",
    "        *examples,  # exemplos few-shot\n",
    "        (\"human\", \"{input}\")  # entrada do usuário\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Renderizando o prompt com uma nova pergunta\n",
    "formatted_prompt = prompt.format_messages(input=\"Qual é a fórmula da água?\")\n",
    "for msg in formatted_prompt:\n",
    "    print(f\"{msg.type.upper()}: {msg.content}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv LangChain)",
   "language": "python",
   "name": "meu_ambiente_langchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
